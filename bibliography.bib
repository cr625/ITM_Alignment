@techreport{darpa_itm_baa,
  author    = "{Defense Advanced Research Projects Agency (DARPA)}",
  title     = "{In the Moment (ITM) Broad Agency Announcement, HR001122S0031}",
  institution = "Defense Sciences Office, DARPA",
  year      = "2022",
  month     = "March",
}

@article{badcott_professional_2011,
	title = {Professional values: introduction to the theme},
	volume = {14},
	copyright = {http://www.springer.com/tdm},
	issn = {1386-7423, 1572-8633},
	shorttitle = {Professional values},
	language = {en},
	number = {2},
	urldate = {2024-12-24},
	journal = {Medicine, Health Care and Philosophy},
	author = {Badcott, David},
	month = may,
	year = {2011},
	pages = {185--186},
	file = {PDF:C\:\\Users\\chris\\Zotero\\storage\\F8H2U6ZN\\Badcott - 2011 - Professional values introduction to the theme.pdf:application/pdf},
}



@article{tolmeijer_implementations_2021,
	title = {Implementations in {Machine} {Ethics}: {A} {Survey}},
	volume = {53},
	issn = {0360-0300},
	shorttitle = {Implementations in {Machine} {Ethics}},
	doi = {10.1145/3419633},
	abstract = {Increasingly complex and autonomous systems require machine ethics to maximize the benefits and minimize the risks to society arising from the new technology. It is challenging to decide which type of ethical theory to employ and how to implement it effectively. This survey provides a threefold contribution. First, it introduces a trimorphic taxonomy to analyze machine ethics implementations with respect to their object (ethical theories), as well as their nontechnical and technical aspects. Second, an exhaustive selection and description of relevant works is presented. Third, applying the new taxonomy to the selected works, dominant research patterns, and lessons for the field are identified, and future directions for research are suggested.},
	number = {6},
	journal = {ACM Computing Surveys},
	author = {Tolmeijer, Suzanne and Kneer, Markus and Sarasua, Cristina and Christen, Markus and Bernstein, Abraham},
	month = dec,
	year = {2021},
	keywords = {Machine ethics, artificial morality},
	pages = {132:1--132:38},
	file = {Tolmeijer et al. - 2021 - Implementations in Machine Ethics A Survey.pdf:C\:\\Users\\chris\\Zotero\\storage\\Y3DRFZUB\\Tolmeijer et al. - 2021 - Implementations in Machine Ethics A Survey.pdf:application/pdf},
}

@article{regin_combining_2024,
	title = {Combining {Constraint} {Programming} {Reasoning} with {Large} {Language} {Model} {Predictions}},
	volume = {307},
	copyright = {Creative Commons Attribution 4.0 International license, info:eu-repo/semantics/openAccess},
	issn = {1868-8969},
	doi = {10.4230/LIPICS.CP.2024.25},
	abstract = {Constraint Programming (CP) and Machine Learning (ML) face challenges in text generation due to CP’s struggle with implementing “meaning” and ML’s difficulty with structural constraints. This paper proposes a solution by combining both approaches and embedding a Large Language Model (LLM) in CP. The LLM handles word generation and meaning, while CP manages structural constraints. This approach builds on GenCP, an improved version of On-the-fly Constraint Programming Search (OTFS) using LLM-generated domains. Compared to Beam Search (BS), a standard NLP method, this combined approach (GenCP with LLM) is faster and produces better results, ensuring all constraints are satisfied. This fusion of CP and ML presents new possibilities for enhancing text generation under constraints.},
	language = {en},
	journal = {LIPIcs, Volume 307, CP 2024},
	author = {Régin, Florian and De Maria, Elisabetta and Bonlarron, Alexandre},
	editor = {Shaw, Paul},
	year = {2024},
	note = {Artwork Size: 18 pages, 882452 bytes
ISBN: 9783959773362
Medium: application/pdf
Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	keywords = {Constrained Text Generation, ML alongside CO, ML-augmented CP, Solver and Tools, Theory of computation → Constraint and logic programming},
	pages = {25:1--25:18},
	file = {PDF:C\:\\Users\\chris\\Zotero\\storage\\KQMBFQTE\\Régin et al. - 2024 - Combining Constraint Programming Reasoning with Large Language Model Predictions.pdf:application/pdf},
}


@inproceedings{hotz2024llm,
  author    = {Lothar Hotz and Christian Bähnisch and Sebastian Lubos and Alexander Felfernig and Albert Haag and Johannes Twiefel},
  title     = {Exploiting Large Language Models for the Automated Generation of Constraint Satisfaction Problems},
  booktitle = {Proceedings of the 26th International Workshop on Configuration (ConfWS'24)},
  year      = {2024},
  address   = {Girona, Spain},
  month     = {September 2--3},
  publisher = {CEUR-WS},
  series    = {CEUR Workshop Proceedings, Vol. 3812},
  url       = {http://ceur-ws.org/Vol-3812/},
  note      = {Available at CEUR-WS}
}

@article{stenseke_artificial_2023,
	title = {Artificial virtuous agents: from theory to machine implementation},
	volume = {38},
	issn = {1435-5655},
	shorttitle = {Artificial virtuous agents},
	doi = {10.1007/s00146-021-01325-7},
	abstract = {Virtue ethics has many times been suggested as a promising recipe for the construction of artificial moral agents due to its emphasis on moral character and learning. However, given the complex nature of the theory, hardly any work has de facto attempted to implement the core tenets of virtue ethics in moral machines. The main goal of this paper is to demonstrate how virtue ethics can be taken all the way from theory to machine implementation. To achieve this goal, we critically explore the possibilities and challenges for virtue ethics from a computational perspective. Drawing on previous conceptual and technical work, we outline a version of artificial virtue based on moral functionalism, connectionist bottom–up learning, and eudaimonic reward. We then describe how core features of the outlined theory can be interpreted in terms of functionality, which in turn informs the design of components necessary for virtuous cognition. Finally, we present a comprehensive framework for the technical development of artificial virtuous agents and discuss how they can be implemented in moral environments.},
	language = {en},
	number = {4},
	journal = {AI \& SOCIETY},
	author = {Stenseke, Jakob},
	month = aug,
	year = {2023},
	keywords = {Artificial intelligence, Artificial Intelligence, Moral machine, Machine ethics, Artificial neural networks, Artificial moral agent, Connectionism, Virtue ethics, Medical Ethics},
	pages = {1301--1320},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\AUZB3IX9\\Stenseke - 2023 - Artificial virtuous agents from theory to machine.pdf:application/pdf},
}

@book{hobbs2005scenario,
  title={A scenario-directed computational framework to aid decision-making and systems development},
  author={Hobbs, Reginald L},
  year={2005},
  publisher={Georgia Institute of Technology}
}

@book{abbott_reasonable_2020,
	edition = {1},
	title = {The {Reasonable} {Robot}: {Artificial} {Intelligence} and the {Law}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-1-108-63176-1 978-1-108-47212-8 978-1-108-45902-0},
	shorttitle = {The {Reasonable} {Robot}},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Abbott, Ryan},
	month = jun,
	year = {2020},
	doi = {10.1017/9781108631761},
	file = {PDF:C\:\\Users\\Chris\\Zotero\\storage\\UWBMQY7C\\Abbott - 2020 - The Reasonable Robot Artificial Intelligence and the Law.pdf:application/pdf},
}

@misc{sarmiento_action_2023,
	title = {Action {Languages} {Based} {Actual} {Causality} for {Computational} {Ethics}: a {Sound} and {Complete} {Implementation} in {ASP}},
	shorttitle = {Action {Languages} {Based} {Actual} {Causality} for {Computational} {Ethics}},
	url = {http://arxiv.org/abs/2205.02919},
	doi = {10.48550/arXiv.2205.02919},
	abstract = {Although moral responsibility is not circumscribed by causality, they are both closely intermixed. Furthermore, rationally understanding the evolution of the physical world is inherently linked with the idea of causality. Thus, the decision-making applications based on automated planning inevitably have to deal with causality, especially if they consider imputability aspects or integrate references to ethical norms. The many debates around causation in the last decades have shown how complex this notion is and thus, how difficult is its integration with planning. As a result, much of the work in computational ethics relegates causality to the background, despite the considerations stated above. This paper's contribution is to provide a complete and sound translation into logic programming from an actual causation definition suitable for action languages, this definition is a formalisation of Wright's NESS test. The obtained logic program allows to deal with complex causal relations. In addition to enabling agents to reason about causality, this contribution specifically enables the computational ethics domain to handle situations that were previously out of reach. In a context where ethical considerations in decision-making are increasingly important, advances in computational ethics can greatly benefit the entire AI community.},
	urldate = {2024-06-28},
	publisher = {arXiv},
	author = {Sarmiento, Camilo and Bourgne, Gauvain and Inoue, Katsumi and Cavalli, Daniele and Ganascia, Jean-Gabriel},
	month = may,
	year = {2023},
	note = {arXiv:2205.02919 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:C\:\\Users\\chris\\Zotero\\storage\\HSJUNW3U\\2205.html:text/html;Sarmiento et al. - 2023 - Action Languages Based Actual Causality for Comput.pdf:C\:\\Users\\chris\\Zotero\\storage\\7DVUK5QA\\Sarmiento et al. - 2023 - Action Languages Based Actual Causality for Comput.pdf:application/pdf},
}


@article{wotawa_model-based_2022,
	title = {Model-based reasoning using answer set programming},
	volume = {52},
	issn = {1573-7497},
	url = {https://doi.org/10.1007/s10489-022-03272-2},
	doi = {10.1007/s10489-022-03272-2},
	abstract = {Diagnosis, i.e., the detection and identification of faults, provides the basis for bringing systems back to normal operation in case of a fault. Diagnosis is a very important task of our daily live, assuring safe and reliable behavior of systems. The automation of diagnosis has been a successful research topic for several decades. However, there are limitations due to complexity issues and lack of expressiveness of the underlying reasoning mechanisms. More recently logic reasoning like answer set programming has gained a lot of attention and practical use. In this paper, we tackle the question whether answer set programming can be used for automating diagnosis, focusing on industrial applications. We discuss a formalization of the diagnosis problem based on answer set programming, introduce a general framework for modeling systems, and present experimental results of an answer set programming based diagnosis algorithm. Past limitations like not being able to deal with numerical operations for modeling can be solved to some extent. The experimental results indicate that answer set programming is efficient enough for being used in diagnosis applications, providing that the underlying system is of moderate size. For digital circuits having less than 500 components, diagnosis time has been less than one second even for computing triple fault diagnoses.},
	language = {en},
	number = {15},
	urldate = {2024-07-21},
	journal = {Applied Intelligence},
	author = {Wotawa, Franz and Kaufmann, David},
	month = dec,
	year = {2022},
	keywords = {Answer set programming, Experimental evaluation, Model-based diagnosis, Modeling for diagnosis},
	pages = {16993--17011},
	file = {Full Text PDF:C\:\\Users\\chris\\Zotero\\storage\\3IFWPVA8\\Wotawa and Kaufmann - 2022 - Model-based reasoning using answer set programming.pdf:application/pdf},
}


@book{dubber_oxford_2020,
	address = {New York},
	series = {Oxford handbooks},
	title = {The {Oxford} handbook of ethics of {AI}},
	isbn = {978-0-19-006739-7 978-0-19-760144-0},
	abstract = {This volume tackles a quickly-evolving field of inquiry, mapping the existing discourse as part of a general attempt to place current developments in historical context; at the same time, breaking new ground in taking on novel subjects and pursuing fresh approaches. The term "A.I." is used to refer to a broad range of phenomena, from machine learning and data mining to artificial general intelligence. The recent advent of more sophisticated AI systems, which function with partial or full autonomy and are capable of tasks which require learning and 'intelligence', presents difficult ethical questions, and has drawn concerns from many quarters about individual and societal welfare, democratic decision-making, moral agency, and the prevention of harm. This work ranges from explorations of normative constraints on specific applications of machine learning algorithms today-in everyday medical practice, for instance-to reflections on the (potential) status of AI as a form of consciousness with attendant rights and duties and, more generally still, on the conceptual terms and frameworks necessarily to understand tasks requiring intelligence, whether "human" or "A.I."},
	language = {en},
	publisher = {Oxford university press},
	author = {Dubber, Markus Dirk and Pasquale, Frank and Das, Sunit},
	year = {2020},
	file = {PDF:C\:\\Users\\chris\\Zotero\\storage\\95UNZP89\\Dubber et al. - 2020 - The Oxford handbook of ethics of AI.pdf:application/pdf},
}


@article{kirkscey_identifying_2024,
	title = {Identifying the foundation: {Connecting} codes of ethics, accreditation, values, and social justice to the engineering curriculum},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0},
	issn = {2371-5243},
	shorttitle = {Identifying the foundation},
	url = {https://ojs.library.queensu.ca/index.php/PCEEA/article/view/17077},
	doi = {10.24908/pceea.2023.17077},
	abstract = {Canadian Engineering Accreditation Board (CEAB) graduate attributes are at the foundation of engineering curricular change in Canada. While CEAB graduate attributes require an understanding of ethics, professionalism, and impact, outcomes explicitly associated with equity, diversity, inclusion, indigeneity (EDI-I) and social justice broadly construed are absent. At present, the CEAB ethics criteria imply that understanding and valuing the code of ethics adequately addresses the issue, which leaves a gap in guidance for educators and curriculum designers. This paper reports on a thematic analysis of the 12 Canadian engineering codes of ethics and associated guidelines to discover the values overtly addressed or implied in the documents. We then map these findings onto the values of EDI-I and social justice as outlined by engineering scholars, and we offer recommendations for using the results to guide engineering instructors who want to make appropriate curriculum modifications that will support the CEAB efforts to address these movements.},
	language = {en},
	urldate = {2024-12-28},
	journal = {Proceedings of the Canadian Engineering Education Association (CEEA)},
	author = {Kirkscey, Russell and Vale, Julie and Howcroft, Jennifer},
	month = mar,
	year = {2024},
	file = {PDF:C\:\\Users\\chris\\Zotero\\storage\\IPF52N6S\\Kirkscey et al. - 2024 - Identifying the foundation Connecting codes of ethics, accreditation, values, and social justice to.pdf:application/pdf},
}

@INPROCEEDINGS{zhang2023integrating,
  author    = {Zhang, Haodi and Li, Jiahong and Wang, Yichi and Song, Yuanfeng},
  title     = {Integrating Automated Knowledge Extraction with Large Language Models for Explainable Medical Decision-Making},
  booktitle = {Proceedings of the 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  year      = {2023},
  pages     = {1710--1718}
}

@article{gopalakrishnan2025causality,
  title     = {Causality Extraction from Medical Text Using Large Language Models (LLMs)},
  author    = {Gopalakrishnan, Seethalakshmi and Garbayo, Luciana and Zadrozny, Wlodek},
  journal   = {Information},
  volume    = {16},
  number    = {1},
  pages     = {13},
  year      = {2025},
  publisher = {MDPI}
}

@book{oconnor2019fundamentals,
  title = {Fundamentals of Military Medicine},
  editor = {O'Connor, Francis G. and Schoomaker, Eric B. and Smith, Dale C.},
  publisher = {Office of The Surgeon General, U.S. Army and Borden Institute},
  address = {Fort Sam Houston, TX},
  year = {2019},
  series = {Textbook of Military Medicine},
  isbn = {9780160949609}
}

@misc{jts2025cpgs,
  title = {Clinical Practice Guidelines for Combat Trauma Care},
  author = {{Joint Trauma System}},
  publisher = {Defense Health Agency in partnership with the Joint Trauma System and Committee on Tactical Combat Casualty Care},
  year = {2025},
  url = {https://deployedmedicine.allogy.net/},
  note = {Continuously updated guidelines available through Deployed Medicine platform. Accessed 09 March 2025}
}

@book{beam2003military,
  title = {Military Medical Ethics},
  editor = {Beam, Thomas E. and Sparacino, Linette R.},
  publisher = {Office of The Surgeon General, U.S. Army and Borden Institute},
  address = {Washington, DC},
  year = {2003},
  volume = {1-2},
  isbn = {9780160504778}
}
@book{army2017tccc,
  title = {Tactical Combat Casualty Care Handbook},
  author = {{U.S. Army}},
  edition = {5},
  publisher = {Center for Army Lessons Learned (CALL), U.S. Army Combined Arms Center},
  address = {Fort Leavenworth, KS},
  year = {2017},
  isbn = {9781678198312}
}

@techreport{cotccc2021tccc,
  title = {TCCC Quick Reference},
  author = {{Committee on Tactical Combat Casualty Care}},
  institution = {Joint Trauma System, U.S. Department of Defense},
  year = {2021},
  type = {Technical Report}
}

@book{oakley_virtue_2001,
	title = {Virtue {Ethics} and {Professional} {Roles}},
	isbn = {978-1-139-43218-4},
	abstract = {Professionals, it is said, have no use for simple lists of virtues and vices. The complexities and constraints of professional roles create peculiar moral demands on the people who occupy them, and traits that are vices in ordinary life are praised as virtues in the context of professional roles. Should this disturb us, or is it naive to presume that things should be otherwise? Taking medical and legal practice as key examples, Justin Oakley and Dean Cocking develop a rigorous articulation and defence of virtue ethics, contrasting it with other types of character-based ethical theories and showing that it offers a promising new approach to the ethics of professional roles. They provide insights into the central notions of professional detachment, professional integrity, and moral character in professional life, and demonstrate how a virtue-based approach can help us better understand what ethical professional-client relationships would be like.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Oakley, Justin and Cocking, Dean},
	month = oct,
	year = {2001},
	note = {Google-Books-ID: ZFuDj6uJYLgC},
	keywords = {Law / Ethics \& Professional Responsibility, Philosophy / Political},
}


@inproceedings{molineaux_aligning_2024,
	address = {Cham},
	title = {Aligning to {Human} {Decision}-{Makers} in {Military} {Medical} {Triage}},
	copyright = {All rights reserved},
	isbn = {978-3-031-63646-2},
	doi = {https://doi.org/10.1007/978-3-031-63646-2_24},
	abstract = {Expert human decision makers do not make optimal decisions in realistic domains; their decisions are affected by preferences, ethics, background experience, and contextual factors. Often there is no optimal decision, or any consensus on what makes a decision good. In this paper we consider the problem of aligning decisions to human decision makers. To this end, we introduce a novel formulation of an aligned decision-making problem, and present the Trustworthy Algorithmic Delegate (TAD), an integrated AI system that learns to align its decision-making process to target decision-makers using case-based reasoning, Monte Carlo simulation, Bayesian diagnosis, and Naturalistic decision-making. We apply TAD in a military triage domain, where experts make different decisions, and present experimental results showing that it outperforms baselines and ablations at alignment in this domain. Our primary claims are that the combined components of TAD allows for aligned decision-making using a small, learned case base and that TAD outperforms simpler strategies for alignment in this domain.},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}},
	publisher = {Springer Nature Switzerland},
	author = {Molineaux, Matthew and Weber, Rosina O. and Floyd, Michael W. and Menager, David and Larue, Othalia and Addison, Ursula and Kulhanek, Ray and Reifsnyder, Noah and Rauch, Christopher and Mainali, Mallika and Sen, Anik and Goel, Prateek and Karneeb, Justin and Turner, JT and Meyer, John},
	editor = {Recio-Garcia, Juan A. and Orozco-del-Castillo, Mauricio G. and Bridge, Derek},
	year = {2024},
	pages = {371--387},
}

@inproceedings{armstrong_motivated_2015,
	title = {Motivated {Value} {Selection} for {Artificial} {Agents}.},
	volume = {92},
	booktitle = {{AAAI} {Workshop}: {AI} and {Ethics}},
	author = {Armstrong, Stuart},
	year = {2015},
	pages = {12--20},
	file = {PDF:C\:\\Users\\Chris\\Zotero\\storage\\3GDPDTLY\\Armstrong - Motivated Value Selection for Artificial Agents.pdf:application/pdf},
}

@article{anderson_machine_2007,
	title = {Machine {Ethics}: {Creating} an {Ethical} {Intelligent} {Agent}},
	volume = {28},
	language = {en},
	journal = {AI Magazine},
	author = {Anderson, Michael},
	year = {2007},
	file = {PDF:C\:\\Users\\Chris\\Zotero\\storage\\AC2S4PPH\\Anderson - Machine Ethics Creating an Ethical Intelligent Agent.pdf:application/pdf},
}

@techreport{tabassi_artificial_2023,
	address = {Gaithersburg, MD},
	title = {Artificial {Intelligence} {Risk} {Management} {Framework} ({AI} {RMF} 1.0)},
	abstract = {As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the AI RMF is to offer a resource to the organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustworthy and responsible development and use of AI systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework.   The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms.},
	language = {en},
	number = {NIST AI 100-1},
	institution = {National Institute of Standards and Technology (U.S.)},
	author = {Tabassi, Elham},
	month = jan,
	year = {2023},
	doi = {10.6028/NIST.AI.100-1},
	pages = {NIST AI 100--1},
	file = {Tabassi - 2023 - Artificial Intelligence Risk Management Framework .pdf:C\:\\Users\\Chris\\Zotero\\storage\\I2BIU4WS\\Tabassi - 2023 - Artificial Intelligence Risk Management Framework .pdf:application/pdf},
}


@inproceedings{rao_what_2023,
	address = {Singapore},
	title = {What {Makes} it {Ok} to {Set} a {Fire}? {Iterative} {Self}-distillation of {Contexts} and {Rationales} for {Disambiguating} {Defeasible} {Social} and {Moral} {Situations}},
	shorttitle = {What {Makes} it {Ok} to {Set} a {Fire}?},
	doi = {10.18653/v1/2023.findings-emnlp.812},
	abstract = {Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios. We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a student model that produces defeasible contexts with improved validity, diversity, and defeasibility. From this model we distill a high-quality dataset, δ-Rules-of-Thumb, of 1.2M entries of contextualizations and rationales for 115K defeasible moral actions rated highly by human annotators 85.9\% to 99.8\% of the time. Using δ-RoT we obtain a final student model that wins over all intermediate student models by a notable margin.},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Rao, Kavel and Jiang, Liwei and Pyatkin, Valentina and Gu, Yuling and Tandon, Niket and Dziri, Nouha and Brahman, Faeze and Choi, Yejin},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	month = dec,
	year = {2023},
	pages = {12140--12159},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\NU53U2RS\\Rao et al. - 2023 - What Makes it Ok to Set a Fire Iterative Self-distillation of Contexts and Rationales for Disambigu.pdf:application/pdf},
}



@article{coin_using_2022,
	title = {Using {Algorithms} to {Make} {Ethical} {Judgements}: {METHAD} vs. the {ADC} {Model}},
	volume = {22},
	issn = {1526-5161},
	shorttitle = {Using {Algorithms} to {Make} {Ethical} {Judgements}},
	doi = {10.1080/15265161.2022.2075967},
	number = {7},
	journal = {The American Journal of Bioethics},
	author = {Coin, Allen and Dubljević, Veljko},
	month = jul,
	year = {2022},
	pmid = {35737500},
	pages = {41--43},
	file = {Coin and Dubljević - 2022 - Using Algorithms to Make Ethical Judgements METHA.pdf:C\:\\Users\\Chris\\Zotero\\storage\\X4ZBGBJ2\\Coin and Dubljević - 2022 - Using Algorithms to Make Ethical Judgements METHA.pdf:application/pdf},
}

@book{wallach_moral_2009,
	address = {Oxford ; New York},
	title = {Moral machines: teaching robots right from wrong},
	isbn = {978-0-19-537404-9},
	shorttitle = {Moral machines},
	language = {en},
	publisher = {Oxford University Press},
	author = {Wallach, Wendell and Allen, Colin},
	year = {2009},
	note = {OCLC: ocn214322641},
	keywords = {Robotics, Computers, Social aspects, Moral and ethical aspects},
	file = {Wallach and Allen - 2009 - Moral machines teaching robots right from wrong.pdf:C\:\\Users\\chris\\Zotero\\storage\\HVNM94B6\\Wallach and Allen - 2009 - Moral machines teaching robots right from wrong.pdf:application/pdf},
}



@article{awad_computational_2022,
	title = {Computational ethics},
	volume = {26},
	issn = {1364-6613},
	doi = {10.1016/j.tics.2022.02.009},
	abstract = {Technological advances are enabling roles for machines that present novel ethical challenges. The study of 'AI ethics' has emerged to confront these challenges, and connects perspectives from philosophy, computer science, law, and economics. Less represented in these interdisciplinary efforts is the perspective of cognitive science. We propose a framework – computational ethics – that specifies how the ethical challenges of AI can be partially addressed by incorporating the study of human moral decision-making. The driver of this framework is a computational version of reflective equilibrium (RE), an approach that seeks coherence between considered judgments and governing principles. The framework has two goals: (i) to inform the engineering of ethical AI systems, and (ii) to characterize human moral judgment and decision-making in computational terms. Working jointly towards these two goals will create the opportunity to integrate diverse research questions, bring together multiple academic communities, uncover new interdisciplinary research topics, and shed light on centuries-old philosophical questions.},
	number = {5},
	journal = {Trends in Cognitive Sciences},
	author = {Awad, Edmond and Levine, Sydney and Anderson, Michael and Anderson, Susan Leigh and Conitzer, Vincent and Crockett, M. J. and Everett, Jim A. C. and Evgeniou, Theodoros and Gopnik, Alison and Jamison, Julian C. and Kim, Tae Wan and Liao, S. Matthew and Meyer, Michelle N. and Mikhail, John and Opoku-Agyemang, Kweku and Borg, Jana Schaich and Schroeder, Juliana and Sinnott-Armstrong, Walter and Slavkovik, Marija and Tenenbaum, Josh B.},
	month = may,
	year = {2022},
	keywords = {computation, AI ethics, machine ethics, ethics, moral cognition, moral psychology},
	pages = {388--405},
	file = {Awad et al. - 2022 - Computational ethics.pdf:C\:\\Users\\Chris\\Zotero\\storage\\LB22UDPN\\Awad et al. - 2022 - Computational ethics.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Chris\\Zotero\\storage\\MXZH2JQW\\S1364661322000456.html:text/html},
}

@incollection{moertl_macrocognition_2008,
	title = {Macrocognition in {Systems} {Engineering}: {Supporting} {Changes} in the {Air} {Traffic}},
	language = {en},
	booktitle = {Naturalistic {Decision} {Making} and {Macrocognitio}},
	publisher = {Ashgate Publishing, Ltd.},
	author = {Moertl, Peter and Bonaceto, Craig and Estes, Steven and Burns, Kevin},
	year = {2008},
	file = {PDF:C\:\\Users\\Chris\\Zotero\\storage\\RB3JMF3P\\Moertl et al. - Supporting Changes in the Air Trafﬁc.pdf:application/pdf},
}


@article{dawson_professional_1994,
	title = {Professional {Codes} of {Practice} and {Ethical} {Conduct}},
	volume = {11},
	issn = {1468-5930},
	doi = {10.1111/j.1468-5930.1994.tb00104.x},
	abstract = {This essay is an attempt to examine the idea that a professional code of practice can entail ethical conduct. It is focused around two differing perspectives on ethics. It will be argued that the professions have, perhaps too hastily, adopted one theory without considering the merits, or the objections offered by the alternative account. This alternative, a ‘cognitivist’ theory, is sketched, and the possible advantages of such an approach are discussed. Such a perspective means adopting a radically different approach to the nature of ethics and what it is to be a moral agent, and could have interesting consequences for professional practice. Even if a cognitivist account is ultimately unconvincing, it does provide a number of worrying arguments for those professionals who believe that ethical conduct is generated by following a code of practice, and these arguments need to be addressed.},
	language = {en},
	number = {2},
	journal = {Journal of Applied Philosophy},
	author = {Dawson, Angus James},
	year = {1994},
	pages = {145--153},
	file = {PDF:C\:\\Users\\Chris\\Zotero\\storage\\JUED8STD\\Dawson - 1994 - Professional Codes of Practice and Ethical Conduct.pdf:application/pdf;Snapshot:C\:\\Users\\Chris\\Zotero\\storage\\EQZMAXPN\\j.1468-5930.1994.tb00104.html:text/html},
}


@misc{bai_constitutional_2022,
	title = {Constitutional {AI}: {Harmlessness} from {AI} {Feedback}},
	shorttitle = {Constitutional {AI}},
	abstract = {As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.},
	publisher = {https://ui.adsabs.harvard.edu},
	author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Hernandez, Danny and Drain, Dawn and Ganguli, Deep and Li, Dustin and Tran-Johnson, Eli and Perez, Ethan and Kerr, Jamie and Mueller, Jared and Ladish, Jeffrey and Landau, Joshua and Ndousse, Kamal and Lukosuite, Kamile and Lovitt, Liane and Sellitto, Michael and Elhage, Nelson and Schiefer, Nicholas and Mercado, Noemi and DasSarma, Nova and Lasenby, Robert and Larson, Robin and Ringer, Sam and Johnston, Scott and Kravec, Shauna and El Showk, Sheer and Fort, Stanislav and Lanham, Tamera and Telleen-Lawton, Timothy and Conerly, Tom and Henighan, Tom and Hume, Tristan and Bowman, Samuel R. and Hatfield-Dodds, Zac and Mann, Ben and Amodei, Dario and Joseph, Nicholas and McCandlish, Sam and Brown, Tom and Kaplan, Jared},
	month = dec,
	year = {2022},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\9QAIFXXL\\Bai et al. - 2022 - Constitutional AI Harmlessness from AI Feedback.pdf:application/pdf},
}

@article{gurney_tactical_2020,
	title = {Tactical {Combat} {Casualty} {Care} {Training}, {Knowledge}, and {Utilization} in the {US} {Army}},
	volume = {185},
	issn = {0026-4075},
	doi = {10.1093/milmed/usz303},
	abstract = {Tactical Combat Casualty Care (TCCC) is the execution of prehospital trauma skills in the combat environment. TCCC was recognized by the 2018 Department of Defense Instruction on Medical Readiness Training as a critical wartime task. This study examines the training, understanding, and utilization of TCCC principles and guidelines among US Army medical providers and examines provider confidence of medics in performing TCCC skills.A cross-sectional survey, developed by members of the Committee on TCCC, was distributed to all US Army Physicians and Physician Assistants via anonymous electronic communication.A total of 613 completed surveys were included in the analyses. Logistic regression analyses were conducted on: TCCC test score of 80\% or higher, confidence with medic utilization of TCCC, and medic utilization of ketamine in accordance with TCCC.\&lt;60\% of respondents expressed confidence in the ability of the medics to perform all TCCC skills. Supervising providers who that believed 80 to 100\% of their medics had completed TCCC training had more confidence in their medic’s TCCC abilities. With TCCC, a recognized lifesaver on the battlefield, continued training and utilization of TCCC concepts are paramount for deploying personnel.},
	number = {Supplement\_1},
	journal = {Military Medicine},
	author = {Gurney, Jennifer M and Stern, Caryn A and Kotwal, Russ S and Cunningham, Cord W and Burelison, Dallas R and Gross, Kirby R and Montgomery, MSG, Harold R and Whitt, MSG, Edward H and Murray, Clinton K and Stockinger, Zsolt T and Butler, Frank K and Shackelford, Stacy A},
	month = jan,
	year = {2020},
	pages = {500--507},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\347JK9B9\\Gurney et al. - 2020 - Tactical Combat Casualty Care Training, Knowledge, and Utilization in the US Army.pdf:application/pdf;Snapshot:C\:\\Users\\Chris\\Zotero\\storage\\B2NPWBFT\\5740662.html:text/html},
}

@article{murray_competence_2021,
	title = {Competence in {Decision} {Making}: {Setting} {Performance} {Standards} for {Critical} {Care}},
	volume = {133},
	issn = {0003-2999},
	shorttitle = {Competence in {Decision} {Making}},
	doi = {10.1213/ANE.0000000000005053},
	language = {en-US},
	number = {1},
	journal = {Anesthesia \& Analgesia},
	author = {Murray, David J. and Boulet, John R. and Boyle, Walter A. and Beyatte, Mary Beth and Woodhouse, Julie},
	month = jul,
	year = {2021},
	pages = {142},
	file = {Snapshot:C\:\\Users\\Chris\\Zotero\\storage\\6ELCW42G\\competence_in_decision_making__setting_performance.20.html:text/html},
}

@article{tahernejad_application_2024,
	title = {Application of artificial intelligence in triage in emergencies and disasters: a systematic review},
	volume = {24},
	issn = {1471-2458},
	shorttitle = {Application of artificial intelligence in triage in emergencies and disasters},
	doi = {10.1186/s12889-024-20447-3},
	abstract = {Modern and intelligent triage systems are used today due to the growing trend of disasters and emergencies worldwide and the increase in the number of injured people facing the challenge of using traditional triage methods. The main objective of this study is to investigate the application of artificial intelligence and Technology in the triage of patients injured by disasters and emergencies and the challenges of the implementation of intelligent triage systems.},
	number = {1},
	journal = {BMC Public Health},
	author = {Tahernejad, Azadeh and Sahebi, Ali and Abadi, Ali Salehi Sahl and Safari, Mehdi},
	month = nov,
	year = {2024},
	keywords = {AI, Artificial intelligence, Data mining, Disasters, Emergencies, Machine learning, Mass casualty, Smart, Systematic review, Triage},
	pages = {3203},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\BI2XIK4H\\Tahernejad et al. - 2024 - Application of artificial intelligence in triage in emergencies and disasters a systematic review.pdf:application/pdf;Snapshot:C\:\\Users\\Chris\\Zotero\\storage\\DHNZT9UZ\\s12889-024-20447-3.html:text/html},
}

@article{gaudaen_usability_2023,
	title = {Usability {Enhancements} to a {Prototype} {Clinical} {Decision} {Support} {System} for {Combat} {Medics}},
	volume = {188},
	issn = {0026-4075},
	doi = {10.1093/milmed/usad279},
	abstract = {A Clinical Decision Support System that provides just-in-time medical guidance at the point of injury is being developed. To develop a user interface, a user-centered design approach was taken.To evaluate the system, personas of the users were created, a comparative analysis of the system against the Tactical Combat Casualty Care Card and Battlefield Assisted Trauma Distributed Observation Kit was completed, and user testing was performed.Many design recommendations were gathered from the user-centered design approach including replacing buttons with a homunculus, replacing prompts with a tree and node system, and allowing more user freedom in working with the system.Through multiple different evaluations, design recommendations for a clinical decision support system were implemented in an iterative process. More iterations and more formalized user testing are planned to maximize the usability of the system.},
	number = {Supplement\_6},
	journal = {Military Medicine},
	author = {Gaudaen, James C and Papadopoulos, Amy and Dockery, Tee and Manemeit, Carl},
	month = nov,
	year = {2023},
	pages = {614--620},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\B7HGRGB5\\Gaudaen et al. - 2023 - Usability Enhancements to a Prototype Clinical Decision Support System for Combat Medics.pdf:application/pdf;Snapshot:C\:\\Users\\Chris\\Zotero\\storage\\TPMH9ZSF\\7388300.html:text/html},
}



@article{thornton_incorporating_2017,
	title = {Incorporating {Ethical} {Considerations} {Into} {Automated} {Vehicle} {Control}},
	volume = {18},
	issn = {1558-0016},
	doi = {10.1109/TITS.2016.2609339},
	number = {6},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Thornton, Sarah M. and Pan, Selina and Erlien, Stephen M. and Gerdes, J. Christian},
	month = jun,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Autonomous automobiles, Autonomous vehicles, ethics, Ethics, Law, model predictive control, Optimization, Roads, vehicle control, Vehicles},
	pages = {1429--1439},
	file = {Full Text PDF:C\:\\Users\\Chris\\Zotero\\storage\\UGS5U2GH\\Thornton et al. - 2017 - Incorporating Ethical Considerations Into Automated Vehicle Control.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Chris\\Zotero\\storage\\JKW85C7H\\7588150.html:text/html},
}


